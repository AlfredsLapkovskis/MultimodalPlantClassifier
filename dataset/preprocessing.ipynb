{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root = os.path.abspath(\"..\")\n",
    "sys.path.append(root)\n",
    "\n",
    "from config import Config\n",
    "from common.constants import IMAGE_SHAPE_WITHOUT_CHANNELS, MODALITY_SET\n",
    "from plant_clef_meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Config(os.path.join(root, \"config.json\"))\n",
    "ORGANS = MODALITY_SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading & Caching Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67812"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = PlantClefImage.load(CONFIG, from_cache=True)\n",
    "meta = [img for img in meta if img.content in ORGANS]\n",
    "\n",
    "PlantClefImage.save(CONFIG, meta, pretty=True)\n",
    "\n",
    "len(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Fat File\n",
    "##### Saves it at path `CONFIG.get_plant_clef_fat_file_path()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fat_file = False  # <<<<<<< SET TO TRUE TO SAVE\n",
    "\n",
    "if save_fat_file:\n",
    "    fat_file_path = CONFIG.get_plant_clef_fat_file_path()\n",
    "    os.makedirs(os.path.dirname(fat_file_path), exist_ok=True)\n",
    "\n",
    "    with open(fat_file_path, \"wb\") as fat_file:\n",
    "        count = len(meta)\n",
    "\n",
    "        for i, m in enumerate(meta):\n",
    "            path = m.get_image_file_path(CONFIG)\n",
    "\n",
    "            with Image.open(path) as img:\n",
    "                if img.mode != \"RGB\":\n",
    "                    img = img.convert(\"RGB\")\n",
    "\n",
    "                img = img.resize(IMAGE_SHAPE_WITHOUT_CHANNELS)\n",
    "                data = img.getdata()\n",
    "                data = list(np.reshape(data, -1))\n",
    "            fat_file.write(bytes(data))\n",
    "\n",
    "            print(f\"\\rFinished {i + 1}/{count}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Organ Indices and Corresponding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_indices = {o: [] for o in ORGANS}\n",
    "organ_labels = {o: [] for o in ORGANS}\n",
    "\n",
    "for i, img in enumerate(meta):\n",
    "    organ = img.content\n",
    "    if organ not in ORGANS:\n",
    "        continue\n",
    "\n",
    "    organ_indices[organ].append(i)\n",
    "    organ_labels[organ].append(img.class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Small Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_organ_indices = organ_indices.copy()\n",
    "filtered_organ_labels = organ_labels.copy()\n",
    "\n",
    "removed_organ_labels = {o: set() for o in ORGANS}\n",
    "\n",
    "for organ in ORGANS:\n",
    "    counter = Counter(filtered_organ_labels[organ])\n",
    "\n",
    "    for label, count in counter.items():\n",
    "        if count < 10:\n",
    "            removed_organ_labels[organ].add(label)\n",
    "\n",
    "for organ in ORGANS:\n",
    "    indices = filtered_organ_indices[organ]\n",
    "    labels = filtered_organ_labels[organ]\n",
    "    removed_labels = removed_organ_labels[organ]\n",
    "\n",
    "    filtered_organ_indices[organ] = [index for i, index in enumerate(indices) if labels[i] not in removed_labels]\n",
    "    filtered_organ_labels[organ] = [label for label in labels if label not in removed_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Leaf', 449), ('Flower', 862), ('Fruit', 302), ('Stem', 146)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, len(set(x))) for k, x in filtered_organ_labels.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Labels To [0; N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_class_distribution(meta, included_labels):\n",
    "    classes = {}\n",
    "\n",
    "    for img in meta:\n",
    "        cls = img.class_id\n",
    "        if cls in included_labels:\n",
    "            classes[cls] = (classes[cls] + 1) if cls in classes else 1\n",
    "    \n",
    "    return np.array(sorted(classes.items(), key=lambda i: i[1], reverse=True))\n",
    "\n",
    "class_dist = get_class_distribution(meta, set(chain(*filtered_organ_labels.values())))\n",
    "class_map = {c: i for i, c in enumerate(class_dist[:, 0])}\n",
    "\n",
    "mapped_filtered_organ_labels = filtered_organ_labels.copy()\n",
    "\n",
    "for organ in ORGANS:\n",
    "    labels = mapped_filtered_organ_labels[organ]\n",
    "    mapped_filtered_organ_labels[organ] = [class_map[label] for label in labels]\n",
    "\n",
    "len(class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {}\n",
    "X_valid = {}\n",
    "X_test = {}\n",
    "\n",
    "y_train = {}\n",
    "y_valid = {}\n",
    "y_test = {}\n",
    "\n",
    "for organ, indices in filtered_organ_indices.items():\n",
    "    labels = mapped_filtered_organ_labels[organ]\n",
    "\n",
    "    train_indices, test_indices, train_labels, test_labels = train_test_split(indices, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "    train_indices, valid_indices, train_labels, valid_labels = train_test_split(train_indices, train_labels, test_size=0.2 / 0.8, shuffle=True, stratify=train_labels)\n",
    "\n",
    "    X_train[organ] = train_indices\n",
    "    X_valid[organ] = valid_indices\n",
    "    X_test[organ] = test_indices\n",
    "\n",
    "    y_train[organ] = train_labels\n",
    "    y_valid[organ] = valid_labels\n",
    "    y_test[organ] = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output split sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4450, 2769, 21606, 8448],\n",
       " [4450, 2769, 21606, 8448],\n",
       " [1484, 923, 7202, 2817],\n",
       " [1484, 923, 7202, 2817],\n",
       " [1484, 924, 7203, 2817],\n",
       " [1484, 924, 7203, 2817])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in X_train.values()], \\\n",
    "[len(y) for y in y_train.values()], \\\n",
    "[len(x) for x in X_valid.values()], \\\n",
    "[len(y) for y in y_valid.values()], \\\n",
    "[len(x) for x in X_test.values()], \\\n",
    "[len(y) for y in y_test.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that data among splits do not intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() set() set()\n",
      "set() set() set()\n",
      "set() set() set()\n",
      "set() set() set()\n"
     ]
    }
   ],
   "source": [
    "for organ in ORGANS:\n",
    "    train = set(X_train[organ])\n",
    "    valid = set(X_valid[organ])\n",
    "    test = set(X_test[organ])\n",
    "\n",
    "    print(f\"{train.intersection(valid)} {train.intersection(test)} {valid.intersection(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output number of classes per modality for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Fruit', 302), ('Stem', 146), ('Flower', 862), ('Leaf', 449)],\n",
       " [('Fruit', 302), ('Stem', 146), ('Flower', 862), ('Leaf', 449)],\n",
       " [('Fruit', 302), ('Stem', 146), ('Flower', 862), ('Leaf', 449)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(o, len(set(y))) for o, y in y_train.items()], \\\n",
    "[(o, len(set(y))) for o, y in y_valid.items()], \\\n",
    "[(o, len(set(y))) for o, y in y_test.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that each modality contains the same classes in each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: 302 302 302, intersections: 302 302 302\n",
      "lengths: 146 146 146, intersections: 146 146 146\n",
      "lengths: 862 862 862, intersections: 862 862 862\n",
      "lengths: 449 449 449, intersections: 449 449 449\n"
     ]
    }
   ],
   "source": [
    "for organ in ORGANS:\n",
    "    train = set(y_train[organ])\n",
    "    valid = set(y_valid[organ])\n",
    "    test = set(y_test[organ])\n",
    "\n",
    "    print(f\"lengths: {len(train)} {len(valid)} {len(test)}, intersections: {len(train.intersection(valid))} {len(train.intersection(test))} {len(valid.intersection(test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Unimodal Files\n",
    "\n",
    "##### Saves them at path `CONFIG.get_unimodal_csv_file_path(split_name, modality)`, for example:\n",
    "```python\n",
    "CONFIG.get_unimodal_csv_file_path(\"train\", \"Flower\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False  # <<<<<<< SET TO TRUE TO SAVE\n",
    "\n",
    "\n",
    "def save_unimodal_split(X, y, organ, split_name):\n",
    "    df = pd.DataFrame({\n",
    "        \"Image\": X[organ],\n",
    "        \"Label\": y[organ],\n",
    "    })\n",
    "\n",
    "    csv_path = CONFIG.get_unimodal_csv_file_path(split_name, organ)\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "if save:\n",
    "    for organ in ORGANS:\n",
    "        save_unimodal_split(X_train, y_train, organ, \"train\")\n",
    "        save_unimodal_split(X_valid, y_valid, organ, \"validation\")\n",
    "        save_unimodal_split(X_test, y_test, organ, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Multimodal Combinations\n",
    "\n",
    "##### Saves them at path `CONFIG.get_multimodal_csv_file_path(split_name)`, for example:\n",
    "```python\n",
    "CONFIG.get_multimodal_csv_file_path(\"train\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate = False  # <<<<<<< SET TO TRUE TO GENERATE\n",
    "\n",
    "\n",
    "def generate_multimodal_combinations(split_name):\n",
    "    paths = {o: CONFIG.get_unimodal_csv_file_path(split_name, o) for o in ORGANS}\n",
    "    dfs = {o: pd.read_csv(path) for o, path in paths.items()}\n",
    "\n",
    "    labels = np.unique(list(chain(*[df[\"Label\"] for df in dfs.values()])))\n",
    "\n",
    "    combinations = {\n",
    "        **{o: [] for o in ORGANS},\n",
    "        \"Label\": [],\n",
    "    }\n",
    "\n",
    "    for label in labels:\n",
    "        organ_values = [(o, df[df[\"Label\"] == label][\"Image\"]) for o, df in dfs.items()]\n",
    "        organ_values = [(o, v) for o, v in organ_values if len(v) > 0]\n",
    "\n",
    "        sorted_organ_values = sorted(organ_values, key=lambda x: len(x[1]), reverse=True)\n",
    "        assert sorted_organ_values\n",
    "\n",
    "        n_combinations = len(sorted_organ_values[0][1])\n",
    "        assert n_combinations > 0\n",
    "\n",
    "        organ_names = [x[0] for x in sorted_organ_values]\n",
    "        organ_values = [x[1] for x in sorted_organ_values]\n",
    "\n",
    "        organ_values = [np.random.permutation(values) for values in organ_values]\n",
    "        organ_values = [np.resize(values, n_combinations) for values in organ_values]\n",
    "        organ_values = [iter(values) for values in organ_values]\n",
    "\n",
    "        organ_names_values = dict(zip(organ_names, organ_values))\n",
    "\n",
    "        combinations[\"Label\"].extend(np.repeat(label, n_combinations))\n",
    "\n",
    "        for _ in range(n_combinations):\n",
    "            for organ in ORGANS:\n",
    "                if organ in organ_names_values:\n",
    "                    value = next(organ_names_values[organ])\n",
    "                    combinations[organ].append(value)\n",
    "                else:\n",
    "                    combinations[organ].append(None)\n",
    "\n",
    "    df = pd.DataFrame(combinations).sample(frac=1)\n",
    "\n",
    "    csv_path = CONFIG.get_multimodal_csv_file_path(split_name)\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "if generate:\n",
    "    generate_multimodal_combinations(\"train\")\n",
    "    generate_multimodal_combinations(\"validation\")\n",
    "    generate_multimodal_combinations(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
